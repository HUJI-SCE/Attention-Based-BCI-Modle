Data Preprocessing:
The preprocessing will be preformed in stages:
Stage0: The original orientation of the data, as is read from the database - the variable for this is "raw" (from mne).
Stage1: The data is cutoff at a cutoff point (in the current case (BIJVZD): 3_008_700), due to what is most likely
        false data - a shape similar to a Sin wave, with amplitude orders of magnitude greater than the rest of the data
        up to that point.
Stage2: The data is batched - every n samples (of all channels) are put into a separate matrix
        of dimensions (<number of channels>, n), where n is the window size of the batch (and of the kernel in the net).
Stage3: The batches order is randomize - this is a common practice that improves the learning abilities of the net.
        TODO: research this practice
Stage4: The last channel (the status channel - which serves as the solution set) is removed from the tensor,
        and instead a boolean representing the solution set of that batch (whether the button has been pressed or not),
        is joined as a tuple to the batch - so each batch consists of a data set matrix and a the solution set -
        the boolean.
